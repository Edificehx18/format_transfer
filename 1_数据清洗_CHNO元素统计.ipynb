{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import keras\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "data = pd.read_csv(r'./SMILES_entry.csv',sep=',',usecols=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SMILES\n",
      "0              OOC1(OO)CCC(OO)(OO)CC1\n",
      "1         OOC(OO)C1=CC=C(C(OO)OO)C=C1\n",
      "2              ON1N=NN=C1NNC2=NN=NN2O\n",
      "3  ON1N=NN=C1CN2N=NC([N+]([O-])=O)=N2\n",
      "4      ON1N=NN=C1C2=NON=C2N=[N+]=[N-]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "{'@', '8', '#', '0', 'H', '.', '\\\\', '(', '2', ')', '-', 'N', 'C', ' ', '1', ']', 'O', '4', '7', '9', '%', '=', '3', '/', '6', '+', '[', 'S', '5'}\n",
      "29 370\n"
     ]
    }
   ],
   "source": [
    "charset = set(\"\".join(list(data.SMILES)))\n",
    "print(len(charset))\n",
    "char_to_int = dict((c,i) for i,c in enumerate(charset))\n",
    "int_to_char = dict((i,c) for i,c in enumerate(charset))\n",
    "embed = max([len(smile) for smile in data.SMILES]) + 5\n",
    "print (str(charset))\n",
    "print(len(charset), embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_to_int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(smiles):\n",
    "        one_hot =  np.zeros((smiles.shape[0], embed , len(charset)),dtype=np.int8)\n",
    "        for i,smile in enumerate(smiles):\n",
    "            #encode the startchar\n",
    "            one_hot[i,0,char_to_int[\"!\"]] = 1\n",
    "            #encode the rest of the chars\n",
    "            for j,c in enumerate(smile):\n",
    "                one_hot[i,j+1,char_to_int[c]] = 1\n",
    "            #Encode endchar\n",
    "            one_hot[i,len(smile)+1:,char_to_int[\"E\"]] = 1\n",
    "        #Return two, one for input and the other for output\n",
    "        return one_hot[:,0:-1,:], one_hot[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _ = vectorize(X_train)\n",
    "X_test, _ = vectorize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_str_train=[]\n",
    "mol_str_test=[]\n",
    "for x in range(3945):\n",
    " \n",
    "    mol_str_train.append(\"\".join([int_to_char[idx] for idx in np.argmax(X_train[x,:,:], axis=1)]))\n",
    "    \n",
    "    \n",
    "for x in range(1315):\n",
    "    mol_str_test.append(\"\".join([int_to_char[idx] for idx in np.argmax(X_test[x,:,:], axis=1)]))\n",
    "\n",
    "# mol_str_train_data=pd.DataFrame(data=mol_str_train)\n",
    "# mol_str_test_data=pd.DataFrame(data=mol_str_test)\n",
    "# mol_str_train_data.to_csv(\"mol_str_train.csv\")\n",
    "# mol_str_test_data.to_csv(\"mol_str_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for x in range(3945):\n",
    "    a = np.argmax(X_train[x,:,:], axis=1)\n",
    "print(a.max())\n",
    "for x in range(1315):\n",
    "    b = np.argmax(X_train[x,:,:], axis=1)\n",
    "print(b.max())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(charset)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Keras: %s\"%keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 68, input_length=embed-1)) # input_dim, output_dim\n",
    "model.add(keras.layers.Conv1D(50,10,activation='relu'))\n",
    "# （批）规范化BatchNormalization\n",
    "# 该层在每个batch上将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1\n",
    "model.add(BatchNormalization())\n",
    "model.add(keras.layers.Conv1D(50,5,activation='relu'))\n",
    "model.add(keras.layers.Conv1D(50,3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(60, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol_str_train = np.asarray(mol_str_train)\n",
    "# mol_str_test = np.asarray(mol_str_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.00025)\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[coeff_determination, lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 213, 68)           2312      \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 204, 50)           34050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 204, 50)           200       \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 200, 50)           12550     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 198, 50)           7550      \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 9900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 9900)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 9901      \n",
      "=================================================================\n",
      "Total params: 66,563\n",
      "Trainable params: 66,463\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3945 samples, validate on 1315 samples\n",
      "Epoch 1/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 26232040.7483 - coeff_determination: 0.2572 - lr: 2.5000e-04 - val_loss: 138687513.7764 - val_coeff_determination: -3.1455 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 138687513.77643, saving model to weights.best.hdf5\n",
      "Epoch 2/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 25852909.7850 - coeff_determination: 0.2573 - lr: 2.5000e-04 - val_loss: 162890142.2966 - val_coeff_determination: -3.8752 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 138687513.77643\n",
      "Epoch 3/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 25791548.1379 - coeff_determination: 0.2667 - lr: 2.5000e-04 - val_loss: 62598946.9293 - val_coeff_determination: -0.8639 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 138687513.77643 to 62598946.92928, saving model to weights.best.hdf5\n",
      "Epoch 4/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 25584961.4114 - coeff_determination: 0.2755 - lr: 2.5000e-04 - val_loss: 91594305.2167 - val_coeff_determination: -1.7357 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 62598946.92928\n",
      "Epoch 5/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 25419229.4743 - coeff_determination: 0.2788 - lr: 2.5000e-04 - val_loss: 63315361.4114 - val_coeff_determination: -0.8876 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 62598946.92928\n",
      "Epoch 6/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24935309.6791 - coeff_determination: 0.2935 - lr: 2.5000e-04 - val_loss: 57521056.3042 - val_coeff_determination: -0.7142 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00006: val_loss improved from 62598946.92928 to 57521056.30418, saving model to weights.best.hdf5\n",
      "Epoch 7/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 25033358.8122 - coeff_determination: 0.2860 - lr: 2.5000e-04 - val_loss: 48021592.6053 - val_coeff_determination: -0.4296 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00007: val_loss improved from 57521056.30418 to 48021592.60532, saving model to weights.best.hdf5\n",
      "Epoch 8/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24858397.0246 - coeff_determination: 0.2950 - lr: 2.5000e-04 - val_loss: 27449091.7932 - val_coeff_determination: 0.1855 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00008: val_loss improved from 48021592.60532 to 27449091.79316, saving model to weights.best.hdf5\n",
      "Epoch 9/50\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 25384175.1027 - coeff_determination: 0.2765 - lr: 2.5000e-04 - val_loss: 27838805.4844 - val_coeff_determination: 0.1738 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 27449091.79316\n",
      "Epoch 10/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24580616.7062 - coeff_determination: 0.3013 - lr: 2.5000e-04 - val_loss: 42275377.3779 - val_coeff_determination: -0.2577 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 27449091.79316\n",
      "Epoch 11/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24571314.6976 - coeff_determination: 0.3035 - lr: 2.5000e-04 - val_loss: 26002787.2928 - val_coeff_determination: 0.2282 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00011: val_loss improved from 27449091.79316 to 26002787.29278, saving model to weights.best.hdf5\n",
      "Epoch 12/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24495096.9658 - coeff_determination: 0.3054 - lr: 2.5000e-04 - val_loss: 28354078.6297 - val_coeff_determination: 0.1581 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 26002787.29278\n",
      "Epoch 13/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24787041.8413 - coeff_determination: 0.2906 - lr: 2.5000e-04 - val_loss: 28411359.9757 - val_coeff_determination: 0.1565 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 26002787.29278\n",
      "Epoch 14/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24257715.3039 - coeff_determination: 0.3153 - lr: 2.5000e-04 - val_loss: 24333325.3886 - val_coeff_determination: 0.2759 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00014: val_loss improved from 26002787.29278 to 24333325.38859, saving model to weights.best.hdf5\n",
      "Epoch 15/50\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 24074720.5435 - coeff_determination: 0.3172 - lr: 2.5000e-04 - val_loss: 26459946.0684 - val_coeff_determination: 0.2151 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 24333325.38859\n",
      "Epoch 16/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23890546.2160 - coeff_determination: 0.3260 - lr: 2.5000e-04 - val_loss: 23885615.4281 - val_coeff_determination: 0.2902 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00016: val_loss improved from 24333325.38859 to 23885615.42814, saving model to weights.best.hdf5\n",
      "Epoch 17/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24054773.4241 - coeff_determination: 0.3172 - lr: 2.5000e-04 - val_loss: 29613817.2578 - val_coeff_determination: 0.1206 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 23885615.42814\n",
      "Epoch 18/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24744792.0512 - coeff_determination: 0.2988 - lr: 2.5000e-04 - val_loss: 26932347.7156 - val_coeff_determination: 0.1970 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 23885615.42814\n",
      "Epoch 19/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 24232704.9369 - coeff_determination: 0.3145 - lr: 2.5000e-04 - val_loss: 24265043.8205 - val_coeff_determination: 0.2786 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 23885615.42814\n",
      "Epoch 20/50\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 23717909.9848 - coeff_determination: 0.3306 - lr: 2.5000e-04 - val_loss: 24167780.9034 - val_coeff_determination: 0.2831 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 23885615.42814\n",
      "Epoch 21/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23825531.5701 - coeff_determination: 0.3219 - lr: 2.5000e-04 - val_loss: 25717020.0106 - val_coeff_determination: 0.2375 - val_lr: 2.5000e-04\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 23885615.42814\n",
      "Epoch 22/50\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 23411744.3559 - coeff_determination: 0.3350 - lr: 2.5000e-05 - val_loss: 23710178.1430 - val_coeff_determination: 0.2968 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00022: val_loss improved from 23885615.42814 to 23710178.14297, saving model to weights.best.hdf5\n",
      "Epoch 23/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23390577.9316 - coeff_determination: 0.3398 - lr: 2.5000e-05 - val_loss: 23539866.2175 - val_coeff_determination: 0.3015 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00023: val_loss improved from 23710178.14297 to 23539866.21749, saving model to weights.best.hdf5\n",
      "Epoch 24/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23447482.4172 - coeff_determination: 0.3352 - lr: 2.5000e-05 - val_loss: 24001855.1087 - val_coeff_determination: 0.2884 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 23539866.21749\n",
      "Epoch 25/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23495019.8003 - coeff_determination: 0.3342 - lr: 2.5000e-05 - val_loss: 24432181.6152 - val_coeff_determination: 0.2757 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 23539866.21749\n",
      "Epoch 26/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23449797.9077 - coeff_determination: 0.3334 - lr: 2.5000e-05 - val_loss: 23596172.3970 - val_coeff_determination: 0.3001 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 23539866.21749\n",
      "Epoch 27/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23385048.9435 - coeff_determination: 0.3304 - lr: 2.5000e-05 - val_loss: 23550443.0008 - val_coeff_determination: 0.3010 - val_lr: 2.5000e-05\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 23539866.21749\n",
      "Epoch 28/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23479602.0451 - coeff_determination: 0.3375 - lr: 2.5000e-05 - val_loss: 23784494.5612 - val_coeff_determination: 0.2947 - val_lr: 2.5000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: val_loss did not improve from 23539866.21749\n",
      "Epoch 29/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23404857.6862 - coeff_determination: 0.3382 - lr: 2.5000e-06 - val_loss: 23560129.8814 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 23539866.21749\n",
      "Epoch 30/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23325698.4796 - coeff_determination: 0.3384 - lr: 2.5000e-06 - val_loss: 23543024.2692 - val_coeff_determination: 0.3014 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 23539866.21749\n",
      "Epoch 31/50\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 23253400.1222 - coeff_determination: 0.3395 - lr: 2.5000e-06 - val_loss: 23545869.9255 - val_coeff_determination: 0.3013 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 23539866.21749\n",
      "Epoch 32/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23272491.2943 - coeff_determination: 0.3355 - lr: 2.5000e-06 - val_loss: 23543557.4601 - val_coeff_determination: 0.3014 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 23539866.21749\n",
      "Epoch 33/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23420168.9724 - coeff_determination: 0.3366 - lr: 2.5000e-06 - val_loss: 23552547.0297 - val_coeff_determination: 0.3010 - val_lr: 2.5000e-06\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 23539866.21749\n",
      "Epoch 34/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23376866.5425 - coeff_determination: 0.3334 - lr: 2.5000e-07 - val_loss: 23551671.7916 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-07\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 23539866.21749\n",
      "Epoch 35/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23309568.3954 - coeff_determination: 0.3378 - lr: 2.5000e-07 - val_loss: 23552018.2357 - val_coeff_determination: 0.3010 - val_lr: 2.5000e-07\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 23539866.21749\n",
      "Epoch 36/50\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 23214456.7721 - coeff_determination: 0.3426 - lr: 2.5000e-07 - val_loss: 23549598.7118 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-07\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 23539866.21749\n",
      "Epoch 37/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23303194.3229 - coeff_determination: 0.3349 - lr: 2.5000e-07 - val_loss: 23548229.8479 - val_coeff_determination: 0.3012 - val_lr: 2.5000e-07\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 23539866.21749\n",
      "Epoch 38/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23319394.2322 - coeff_determination: 0.3402 - lr: 2.5000e-07 - val_loss: 23548939.5316 - val_coeff_determination: 0.3012 - val_lr: 2.5000e-07\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 23539866.21749\n",
      "Epoch 39/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23351499.5838 - coeff_determination: 0.3343 - lr: 2.5000e-08 - val_loss: 23549576.3224 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-08\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 23539866.21749\n",
      "Epoch 40/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23443080.5100 - coeff_determination: 0.3366 - lr: 2.5000e-08 - val_loss: 23549423.1270 - val_coeff_determination: 0.3012 - val_lr: 2.5000e-08\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 23539866.21749\n",
      "Epoch 41/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23385824.3975 - coeff_determination: 0.3354 - lr: 2.5000e-08 - val_loss: 23550175.7080 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-08\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 23539866.21749\n",
      "Epoch 42/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23574120.3493 - coeff_determination: 0.3274 - lr: 2.5000e-08 - val_loss: 23549241.7323 - val_coeff_determination: 0.3012 - val_lr: 2.5000e-08\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 23539866.21749\n",
      "Epoch 43/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23424652.3224 - coeff_determination: 0.3351 - lr: 2.5000e-08 - val_loss: 23549674.2722 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-08\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 23539866.21749\n",
      "Epoch 44/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23238635.2928 - coeff_determination: 0.3360 - lr: 2.5000e-09 - val_loss: 23549103.8494 - val_coeff_determination: 0.3012 - val_lr: 2.5000e-09\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 23539866.21749\n",
      "Epoch 45/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23244853.5635 - coeff_determination: 0.3412 - lr: 2.5000e-09 - val_loss: 23549377.6213 - val_coeff_determination: 0.3012 - val_lr: 2.5000e-09\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 23539866.21749\n",
      "Epoch 46/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23474400.9901 - coeff_determination: 0.3342 - lr: 2.5000e-09 - val_loss: 23549791.6715 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-09\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 23539866.21749\n",
      "Epoch 47/50\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 23541695.6684 - coeff_determination: 0.3303 - lr: 2.5000e-09 - val_loss: 23549268.4243 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-09\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 23539866.21749\n",
      "Epoch 48/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23382103.4139 - coeff_determination: 0.3371 - lr: 2.5000e-09 - val_loss: 23549738.4578 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-09\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 23539866.21749\n",
      "Epoch 49/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23318654.7240 - coeff_determination: 0.3409 - lr: 2.5000e-10 - val_loss: 23549329.0449 - val_coeff_determination: 0.3011 - val_lr: 2.5000e-10\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 23539866.21749\n",
      "Epoch 50/50\n",
      "3945/3945 [==============================] - 11s 3ms/step - loss: 23401172.8548 - coeff_determination: 0.3367 - lr: 2.5000e-10 - val_loss: 23549269.5954 - val_coeff_determination: 0.3012 - val_lr: 2.5000e-10\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 23539866.21749\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "# 定义学习率之后，经过一定epoch迭代之后，模型效果不再提升，该学习率可能已经不再适应该模型。需要在训练过程中缩小学习率，进而提升模型。\n",
    "# 使用keras中的回调函数ReduceLROnPlateau\n",
    "\n",
    "# monitor：监测的值，可以是accuracy，val_loss,val_accuracy\n",
    "# factor：缩放学习率的值，学习率将以lr = lr*factor的形式被减少\n",
    "# patience：当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发\n",
    "# mode：‘auto’，‘min’，‘max’之一 默认‘auto’就行\n",
    "# epsilon：阈值，用来确定是否进入检测值的“平原区”\n",
    "# cooldown：学习率减少后，会经过cooldown个epoch才重新进行正常操作\n",
    "# min_lr：学习率最小值，能缩小到的下限\n",
    "# ————————————————\n",
    "# monitor=\"val_loss\",\n",
    "#     factor=0.1,\n",
    "#     patience=10,\n",
    "#     verbose=0,\n",
    "#     mode=\"auto\",\n",
    "#     min_delta=0.0001,\n",
    "#     cooldown=0,\n",
    "#     min_lr=0,\n",
    "# 原文链接：https://blog.csdn.net/weixin_44048809/article/details/105711356\n",
    "    \n",
    "callbacks_list = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-15, verbose=0, mode='auto',cooldown=0),\n",
    "    ModelCheckpoint(filepath=\"weights.best.hdf5\", monitor='val_loss', save_best_only=True, verbose=1, mode='auto')   \n",
    "]\n",
    "\n",
    "history =model.fit(x=np.argmax(X_train, axis=2), y=Y_train,\n",
    "                              batch_size=128,\n",
    "                              epochs=50,\n",
    "                              validation_data=(np.argmax(X_test, axis=2),Y_test),\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11276\\3443555648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'val_coeff_determination'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'coeff_determination'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "hist = history.history\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for label in ['val_coeff_determination','coeff_determination']:\n",
    "    plt.subplot(221)\n",
    "    plt.plot(hist[label], label = label)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"coeff_determination\")\n",
    "    \n",
    "for label in ['val_loss','loss']:\n",
    "    plt.subplot(222)\n",
    "    plt.plot(hist[label], label = label)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot( hist['lr'],hist['val_coeff_determination']  )\n",
    "plt.legend()\n",
    "plt.xlabel(\"lr\")\n",
    "plt.ylabel(\"val_coeff_determination\")\n",
    "\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot( hist['lr'],hist['val_loss']  )\n",
    "plt.legend()\n",
    "plt.xlabel(\"lr\")\n",
    "plt.ylabel(\"val_loss\")\n",
    "\n",
    "    \n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
